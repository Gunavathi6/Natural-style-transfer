{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6ab408c-ea3b-4b8f-a0ce-693ce92ecbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\gunav/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Assume content_img and style_img are already loaded as 4D tensors [1, 3, H, W]\n",
    "# with normalized values (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "vgg = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True).features.eval()\n",
    "\n",
    "content_layers = ['21']\n",
    "style_layers = ['0', '5', '10', '19', '28']\n",
    "\n",
    "def get_features(x, model, layers):\n",
    "    features = {}\n",
    "    for name, layer in model._modules.items():\n",
    "        x = layer(x)\n",
    "        if name in layers:\n",
    "            features[name] = x\n",
    "    return features\n",
    "\n",
    "def gram_matrix(tensor):\n",
    "    b, c, h, w = tensor.size()\n",
    "    features = tensor.view(c, h * w)\n",
    "    gram = torch.mm(features, features.t())\n",
    "    return gram / (c * h * w)\n",
    "\n",
    "def de_normalize(tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1)\n",
    "    return (tensor * std + mean).clamp(0,1)\n",
    "\n",
    "def neural_style_transfer(content_img, style_img, steps=300, alpha=1e4, beta=1):\n",
    "    target = content_img.clone().requires_grad_(True)\n",
    "\n",
    "    style_features = get_features(style_img, vgg, style_layers)\n",
    "    content_features = get_features(content_img, vgg, content_layers)\n",
    "    style_grams = {l: gram_matrix(style_features[l]) for l in style_layers}\n",
    "\n",
    "    optimizer = torch.optim.Adam([target], lr=0.003)\n",
    "\n",
    "    for i in range(steps):\n",
    "        target_features = get_features(target, vgg, style_layers + content_layers)\n",
    "\n",
    "        c_loss = torch.mean((target_features['21'] - content_features['21']) ** 2)\n",
    "\n",
    "        s_loss = 0\n",
    "        for layer in style_layers:\n",
    "            target_gram = gram_matrix(target_features[layer])\n",
    "            s_loss += torch.mean((target_gram - style_grams[layer]) ** 2)\n",
    "\n",
    "        total_loss = alpha * c_loss + beta * s_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Step {i}, Loss: {total_loss.item()}\")\n",
    "\n",
    "    return de_normalize(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95985f1-8bbc-4ca1-95c5-b989ba94a86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b982e5-bd5a-4ba9-be49-34d4d30e04d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd721d-5c4a-44d8-a086-ceb514dee05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edb465-4693-4df9-becf-c50009769802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
